{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d249ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Define a transform to normalize the data\n",
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "dataset = torchvision.datasets.MNIST(root=\"./root\", train = True, download=True, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a3b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = dataset[0]\n",
    "# Move the image to the device\n",
    "print(f\"Image shape: {img.shape}, Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adf9a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, Latent_dim):\n",
    "        super().__init__()\n",
    "        self.en_f = nn.Linear(input_dim, hidden_dim)\n",
    "        self.en_mu = nn.Linear(hidden_dim, Latent_dim)\n",
    "        self.en_logvar = nn.Linear(hidden_dim, Latent_dim)\n",
    "        self.re_f = nn.Linear(Latent_dim, hidden_dim)\n",
    "        self.re_out = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "    def reparametersize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = F.relu(self.en_f(x.view(x.size(0), -1))) # æŠŠå›¾åƒå±•å¹³\n",
    "        mu = self.en_mu(hidden)\n",
    "        logvar = self.en_logvar(hidden)\n",
    "\n",
    "        z = self.reparametersize(mu, logvar=logvar)\n",
    "\n",
    "        re_en = F.relu(self.re_f(z))\n",
    "        out = self.re_out(re_en)\n",
    "        return F.sigmoid(out).view(*x.size()), mu, logvar\n",
    "    \n",
    "    def decoder(self, z):\n",
    "        re_en = F.relu(self.re_f(z))\n",
    "        out = F.sigmoid(self.re_out(re_en))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f04a0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "model = VAE(1 * 28 * 28, 256, 20).to(device)\n",
    "train_data = torch.utils.data.DataLoader(dataset, batch_size=1024, shuffle=True)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb46123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import swanlab\n",
    "# å‡è®¾æ‚¨åœ¨å…¶ä»–åœ°æ–¹å®šä¹‰äº† model, optimizer, train_data, device\n",
    "\n",
    "# ... swanlab.init() å’Œ num_epochs å®šä¹‰ä¸å˜ ...\n",
    "\n",
    "num_epochs = 200\n",
    "model.train()\n",
    "\n",
    "for i in range(num_epochs): # i ä»£è¡¨å½“å‰ epoch ç´¢å¼• (0 åˆ° 199)\n",
    "    # ğŸ¯ è¿½è¸ªæœ¬ Epoch çš„ç´¯ç§¯æŸå¤±\n",
    "    total_epoch_loss = 0\n",
    "    total_epoch_bce = 0\n",
    "    total_epoch_kld = 0\n",
    "    \n",
    "    # ç¡®ä¿ optimizer å˜é‡åæ­£ç¡®\n",
    "    # å‡è®¾æ‚¨çš„ä¼˜åŒ–å™¨å˜é‡åä¸º optimizer (å¦‚æœä»æ˜¯ optemizerï¼Œè¯·ä¿®æ­£)\n",
    "    \n",
    "    for batch_idx, (batch_imgs, batch_labels) in enumerate(train_data): \n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        \n",
    "        # 1. å‰å‘ä¼ æ’­\n",
    "        recon_batch, mu, logvar = model(batch_imgs)\n",
    "        \n",
    "        # 2. æ¢¯åº¦æ¸…é›¶\n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        # 3. æŸå¤±è®¡ç®—\n",
    "        BCE = torch.sum(F.binary_cross_entropy(recon_batch, batch_imgs, reduction='none'), dim=(1, 2, 3))\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=-1)\n",
    "        \n",
    "        # KL é€€ç«æƒé‡ï¼šåœ¨ 0 åˆ° 1 ä¹‹é—´çº¿æ€§å¢é•¿\n",
    "        kl_weight = i / num_epochs \n",
    "        \n",
    "        # VAE Lossï¼šå¯¹ BCE + åŠ æƒ KLD çš„ç»“æœè¿›è¡Œæ‰¹é‡å¹³å‡\n",
    "        loss = torch.mean(BCE + kl_weight * KLD)\n",
    "        \n",
    "        # 4. åå‘ä¼ æ’­ä¸ä¼˜åŒ–\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 5. ç´¯åŠ æŸå¤±ï¼ˆç”¨äº Epoch æ€»ç»“ï¼‰\n",
    "        # loss.item() æ˜¯æ‰¹é‡å¹³å‡æŸå¤±ï¼Œéœ€è¦ä¹˜ä»¥æ‰¹é‡å¤§å°ï¼ˆæˆ–ä»…ç´¯åŠ å¹³å‡æŸå¤±ï¼‰\n",
    "        # è¿™é‡Œç´¯åŠ å¹³å‡æŸå¤±ï¼Œæœ€åé™¤ä»¥æ€»æ‰¹æ¬¡æ•°é‡ï¼Œå¾—åˆ°å¹³å‡æŸå¤±\n",
    "        total_epoch_loss += loss.item()\n",
    "        total_epoch_bce += BCE.mean().item()\n",
    "        total_epoch_kld += KLD.mean().item()\n",
    "        \n",
    "        # 6. è®°å½•åˆ° SwanLab (å¯é€‰ï¼šåªè®°å½• Batch çº§åˆ«çš„ç¬æ—¶å€¼)\n",
    "        # SwanLab é€‚åˆè®°å½•æ¯ä¸ª Batch çš„ç¬æ—¶æ•°æ®ï¼Œä»¥ä¾¿åœ¨å›¾è¡¨ä¸Šçœ‹åˆ°è¯¦ç»†æ³¢åŠ¨\n",
    "        swanlab.log({\n",
    "            \"batch_loss/loss\": loss.item(), \n",
    "            \"batch_loss/BCE\": BCE.mean().item(), \n",
    "            \"batch_loss/KLD\": KLD.mean().item()\n",
    "        })\n",
    "        \n",
    "        # ğŸš¨ å¯é€‰ï¼šå¦‚æœæ‚¨ä»æƒ³çœ‹ä¸€äº›è¿›åº¦ï¼Œå¯ä»¥æ¯éš” N ä¸ª Batch æ‰“å°ä¸€æ¬¡ï¼š\n",
    "        # if batch_idx % 100 == 0:\n",
    "        #     print(f\"Epoch [{i+1}/{num_epochs}], Batch [{batch_idx}/{len(train_data)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "    # 7. æ¯ä¸ª Epoch ç»“æŸæ—¶çš„æ€»ç»“æ“ä½œ\n",
    "    avg_epoch_loss = total_epoch_loss / len(train_data)\n",
    "    avg_epoch_bce = total_epoch_bce / len(train_data)\n",
    "    avg_epoch_kld = total_epoch_kld / len(train_data)\n",
    "    \n",
    "    # ğŸ¯ è®°å½• Epoch çº§åˆ«çš„å¹³å‡æŸå¤±\n",
    "    swanlab.log({\n",
    "        \"epoch_loss/avg_loss\": avg_epoch_loss,\n",
    "        \"epoch_loss/avg_BCE\": avg_epoch_bce,\n",
    "        \"epoch_loss/avg_KLD\": avg_epoch_kld\n",
    "    }, step=i)\n",
    "    \n",
    "    # æ‰“å°æœ€ç»ˆçš„ Epoch æ€»ç»“\n",
    "    print(f\"--- Epoch [{i+1}/{num_epochs}] Summary ---\")\n",
    "    print(f\"Avg Loss: {avg_epoch_loss:.4f}, Avg BCE: {avg_epoch_bce:.4f}, Avg KLD: {avg_epoch_kld:.4f}\")\n",
    "    \n",
    "    # 8. ä¿å­˜æ¨¡å‹\n",
    "    torch.save(model.state_dict(), 'model.pt')\n",
    "    print(f\"Model saved at epoch {i+1}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc80d4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    img,_=dataset[random.randint(0,len(dataset))]\n",
    "    recon_x,mu,logvar=model(img.unsqueeze(0).to(device))\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img.view(28,28).numpy())\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(recon_x.view(28,28).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7873b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    latent=torch.randn(1,20).to(device)\n",
    "    recon_x=model.decode(latent)\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(recon_x.view(28,28).cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
